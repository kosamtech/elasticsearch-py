{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "To read more about synonyms, checkout the docs [here](https://www.elastic.co/guide/en/elasticsearch/reference/current/synonyms-apis.html).\n",
    "\n",
    "![synonyms_api_docs](../images/synonyms_api_docs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected tp Elasticsearch!\n",
      "{'cluster_name': 'docker-cluster',\n",
      " 'cluster_uuid': 'iugjHCt8SwCWRVd35xnJ0A',\n",
      " 'name': '5013781c82bc',\n",
      " 'tagline': 'You Know, for Search',\n",
      " 'version': {'build_date': '2025-02-05T22:10:57.067596412Z',\n",
      "             'build_flavor': 'default',\n",
      "             'build_hash': '747663ddda3421467150de0e4301e8d4bc636b0c',\n",
      "             'build_snapshot': False,\n",
      "             'build_type': 'docker',\n",
      "             'lucene_version': '9.12.0',\n",
      "             'minimum_index_compatibility_version': '7.0.0',\n",
      "             'minimum_wire_compatibility_version': '7.17.0',\n",
      "             'number': '8.17.2'}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "HOST = \"http://localhost:9200\"\n",
    "\n",
    "es = Elasticsearch(hosts=HOST)\n",
    "client_info = es.info()\n",
    "print(\"Connected tp Elasticsearch!\")\n",
    "pprint(client_info.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True, 'index': 'my_synonym_index', 'shards_acknowledged': True}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "\n",
    "settings = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"filter\": {\n",
    "                \"synonym_filter\": {\n",
    "                    \"type\": \"synonym\",\n",
    "                    \"synonyms\": [\n",
    "                        \"car, automobile, vehicle\",\n",
    "                        \"tv, television\",\n",
    "                        \"smartphone, mobile, cell phone\",\n",
    "                        \"jupyter, jupyter notebook, jupyterlab\",\n",
    "                        \"jupiter, mars, earth, venus, mercury, saturn, uranus, neptune => planet\"\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"analyzer\": {\n",
    "                \"synonym_analyzer\": {\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\",\n",
    "                        \"synonym_filter\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"index\": {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 0\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"description\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"synonym_analyzer\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"my_synonym_index\"\n",
    "es.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "response = es.indices.create(index=index_name, body=settings)\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 42711.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'errors': False,\n",
      " 'items': [{'index': {'_id': '8vphPJUBq90DZqGOiGbF',\n",
      "                      '_index': 'my_synonym_index',\n",
      "                      '_primary_term': 1,\n",
      "                      '_seq_no': 0,\n",
      "                      '_shards': {'failed': 0, 'successful': 1, 'total': 1},\n",
      "                      '_version': 1,\n",
      "                      'result': 'created',\n",
      "                      'status': 201}},\n",
      "           {'index': {'_id': '8_phPJUBq90DZqGOiGbF',\n",
      "                      '_index': 'my_synonym_index',\n",
      "                      '_primary_term': 1,\n",
      "                      '_seq_no': 1,\n",
      "                      '_shards': {'failed': 0, 'successful': 1, 'total': 1},\n",
      "                      '_version': 1,\n",
      "                      'result': 'created',\n",
      "                      'status': 201}},\n",
      "           {'index': {'_id': '9PphPJUBq90DZqGOiGbF',\n",
      "                      '_index': 'my_synonym_index',\n",
      "                      '_primary_term': 1,\n",
      "                      '_seq_no': 2,\n",
      "                      '_shards': {'failed': 0, 'successful': 1, 'total': 1},\n",
      "                      '_version': 1,\n",
      "                      'result': 'created',\n",
      "                      'status': 201}},\n",
      "           {'index': {'_id': '9fphPJUBq90DZqGOiGbF',\n",
      "                      '_index': 'my_synonym_index',\n",
      "                      '_primary_term': 1,\n",
      "                      '_seq_no': 3,\n",
      "                      '_shards': {'failed': 0, 'successful': 1, 'total': 1},\n",
      "                      '_version': 1,\n",
      "                      'result': 'created',\n",
      "                      'status': 201}},\n",
      "           {'index': {'_id': '9vphPJUBq90DZqGOiGbF',\n",
      "                      '_index': 'my_synonym_index',\n",
      "                      '_primary_term': 1,\n",
      "                      '_seq_no': 4,\n",
      "                      '_shards': {'failed': 0, 'successful': 1, 'total': 1},\n",
      "                      '_version': 1,\n",
      "                      'result': 'created',\n",
      "                      'status': 201}}],\n",
      " 'took': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "operations = []\n",
    "dummy_data = json.load(open(\"../data/synonyms.json\"))\n",
    "for document in tqdm(dummy_data, total=len(dummy_data)):\n",
    "    operations.append({\"index\": {\"_index\": index_name}})\n",
    "    operations.append(document)\n",
    "\n",
    "response = es.bulk(operations=operations)\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching with Synonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s search for terms that should match synonyms. For example, we’ll search for \"vehicle\" (which should match \"car\" or \"automobile\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Results:\n",
      "{'description': 'I love my car and television.'}\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"description\": \"vehicle\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.search(index=index_name, body=query)\n",
    "\n",
    "print(\"Search Results:\")\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Results:\n",
      "{'description': 'I want to go to Mars.'}\n",
      "{'description': 'I want to go to Venus.'}\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"description\": \"planet\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.search(index=index_name, body=query)\n",
    "\n",
    "print(\"Search Results:\")\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding Synonyms for Search-Time Only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to apply synonyms only during search (and not while indexing), you can modify the search query analyzer like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True, 'index': 'my_synonym_index', 'shards_acknowledged': True}\n"
     ]
    }
   ],
   "source": [
    "settings = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"filter\": {\n",
    "                \"synonym_filter\": {\n",
    "                    \"type\": \"synonym\",\n",
    "                    \"synonyms\": [\n",
    "                        \"car, automobile, vehicle\",\n",
    "                        \"tv, television\"\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"analyzer\": {\n",
    "                \"index_analyzer\": {\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\"lowercase\"]\n",
    "                },\n",
    "                \"search_analyzer\": {\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\"lowercase\", \"synonym_filter\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"index\": {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 0\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"description\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"index_analyzer\",\n",
    "                \"search_analyzer\": \"search_analyzer\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "es.indices.delete(index=index_name)\n",
    "response = es.indices.create(index=index_name, body=settings)\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 33182.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'errors': False,\n",
      " 'items': [{'index': {'_id': '9_pnPJUBq90DZqGOV2au',\n",
      "                      '_index': 'my_synonym_index',\n",
      "                      '_primary_term': 1,\n",
      "                      '_seq_no': 0,\n",
      "                      '_shards': {'failed': 0, 'successful': 1, 'total': 1},\n",
      "                      '_version': 1,\n",
      "                      'result': 'created',\n",
      "                      'status': 201}},\n",
      "           {'index': {'_id': '-PpnPJUBq90DZqGOV2au',\n",
      "                      '_index': 'my_synonym_index',\n",
      "                      '_primary_term': 1,\n",
      "                      '_seq_no': 1,\n",
      "                      '_shards': {'failed': 0, 'successful': 1, 'total': 1},\n",
      "                      '_version': 1,\n",
      "                      'result': 'created',\n",
      "                      'status': 201}},\n",
      "           {'index': {'_id': '-fpnPJUBq90DZqGOV2au',\n",
      "                      '_index': 'my_synonym_index',\n",
      "                      '_primary_term': 1,\n",
      "                      '_seq_no': 2,\n",
      "                      '_shards': {'failed': 0, 'successful': 1, 'total': 1},\n",
      "                      '_version': 1,\n",
      "                      'result': 'created',\n",
      "                      'status': 201}},\n",
      "           {'index': {'_id': '-vpnPJUBq90DZqGOV2au',\n",
      "                      '_index': 'my_synonym_index',\n",
      "                      '_primary_term': 1,\n",
      "                      '_seq_no': 3,\n",
      "                      '_shards': {'failed': 0, 'successful': 1, 'total': 1},\n",
      "                      '_version': 1,\n",
      "                      'result': 'created',\n",
      "                      'status': 201}},\n",
      "           {'index': {'_id': '-_pnPJUBq90DZqGOV2au',\n",
      "                      '_index': 'my_synonym_index',\n",
      "                      '_primary_term': 1,\n",
      "                      '_seq_no': 4,\n",
      "                      '_shards': {'failed': 0, 'successful': 1, 'total': 1},\n",
      "                      '_version': 1,\n",
      "                      'result': 'created',\n",
      "                      'status': 201}}],\n",
      " 'took': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "operations = []\n",
    "dummy_data = json.load(open(\"../data/synonyms.json\"))\n",
    "for document in tqdm(dummy_data, total=len(dummy_data)):\n",
    "    operations.append({\"index\": {\"_index\": index_name}})\n",
    "    operations.append(document)\n",
    "\n",
    "response = es.bulk(operations=operations)\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Results:\n",
      "{'description': 'I love my car and television.'}\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"description\": \"vehicle\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.search(index=index_name, body=query)\n",
    "\n",
    "print(\"Search Results:\")\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(hit[\"_source\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
